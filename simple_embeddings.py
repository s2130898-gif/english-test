
  """
  è»½é‡ç‰ˆåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ï¼ˆtransformersã®ã¿ä½¿ç”¨ï¼‰
  """
  import numpy as np
  from typing import List
  from transformers import AutoTokenizer, AutoModel
  import torch

  class SimpleEmbeddings:
      def __init__(self):
          print("ðŸ“¦ è»½é‡AIåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")

          # ã‚ˆã‚Šè»½é‡ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
          model_name = 'distilbert-base-uncased'  # è‹±èªžç‰ˆï¼ˆè»½é‡ï¼‰

          try:
              self.tokenizer = AutoTokenizer.from_pretrained(model_name)
              self.model = AutoModel.from_pretrained(model_name)
              self.model.eval()
              self.dimension = 768
              print(f"âœ… {model_name} ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")
          except Exception as e:
              print(f"ã‚¨ãƒ©ãƒ¼: {e}")
              # ã•ã‚‰ã«è»½é‡ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
              self.tokenizer = None
              self.model = None
              self.dimension = 100

      def encode(self, texts: List[str]) -> np.ndarray:
          if self.model is None:
              # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ©ãƒ³ãƒ€ãƒ ãƒ™ã‚¯ãƒˆãƒ«
              return np.random.rand(len(texts), self.dimension)

          embeddings = []

          with torch.no_grad():
              for text in texts:
                  try:
                      inputs = self.tokenizer(
                          text,
                          return_tensors='pt',
                          truncation=True,
                          max_length=128,  # ã•ã‚‰ã«çŸ­ã
                          padding=True
                      )

                      outputs = self.model(**inputs)
                      # ã‚·ãƒ³ãƒ—ãƒ«ã«CLSãƒˆãƒ¼ã‚¯ãƒ³ã®ã¿ä½¿ç”¨
                      embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()
                      embeddings.append(embedding)
                  except:
                      # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                      embeddings.append(np.random.rand(self.dimension))

          return np.array(embeddings)

      def encode_single(self, text: str) -> List[float]:
          return self.encode([text])[0].tolist()
