
  """
  æ—¥æœ¬èªžå¯¾å¿œSentence-BERTãƒ¢ãƒ‡ãƒ«ï¼ˆæ”¹å–„ç‰ˆï¼‰
  """
  import numpy as np
  from typing import List
  from sentence_transformers import SentenceTransformer
  import re

  class SimpleEmbeddings:
      def __init__(self):
          print("ðŸ“¦ æ—¥æœ¬èªžå¯¾å¿œAIåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")

          # ã‚ˆã‚Šè‰¯ã„æ—¥æœ¬èªžãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
          model_name = 'pkshatech/GLuCoSE-base-ja'  # NTTã®æ—¥æœ¬èªžç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«
          try:
              self.model = SentenceTransformer(model_name)
              print(f"âœ… {model_name}ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")
          except:
              # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
              model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'
              self.model = SentenceTransformer(model_name)
              print(f"âœ… {model_name}ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")

          self.dimension = 768

      def preprocess_japanese(self, text: str) -> str:
          """æ—¥æœ¬èªžãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†"""
          # åŠ©è©žã‚’å‰Šé™¤ï¼ˆç°¡æ˜“ç‰ˆï¼‰
          particles = ['ã¯', 'ãŒ', 'ã‚’', 'ã«', 'ã¸', 'ã¨', 'ã‹ã‚‰', 'ã¾ã§', 'ã§', 'ã®']
          for p in particles:
              text = text.replace(p, ' ')
          # é€£ç¶šã™ã‚‹ã‚¹ãƒšãƒ¼ã‚¹ã‚’1ã¤ã«
          text = re.sub(r'\s+', ' ', text)
          return text.strip()

      def encode(self, texts: List[str]) -> np.ndarray:
          # å‰å‡¦ç†ã‚’é©ç”¨
          processed_texts = [self.preprocess_japanese(t) for t in texts]
          return self.model.encode(processed_texts)

      def encode_single(self, text: str) -> List[float]:
          processed = self.preprocess_japanese(text)
          return self.model.encode([processed])[0].tolist()
